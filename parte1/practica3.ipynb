{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3: Regresión Lineal I - Aprendizaje Automático I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de los modelos predictivos regresivos, quizás uno de los más básicos sea la regresión lineal. Este modelo se basa en considerar que el valor de la variable dependiente a predecir ($y$) se puede obtener como una combinación lineal $f(\\mathbf{x})$ de los atributos o características ($\\mathbf{x}=(x_1, x_2, \\dots, x_n)$).\n",
    "\n",
    "$y=f(\\mathbf{x}) = w_0 + w_1 \\cdot x^1 + w_2 \\cdot x^2 + \\dots + w_n \\cdot x^n = w_0 + \\mathbf{w}^T \\cdot \\mathbf{x}$\n",
    "\n",
    "Por tanto, dado un conjunto de $m$ muestras $(x_i^1, x_i^2, \\dots, x_i^n, y_i)$ el objetivo es encontrar el conjunto de pesos $w_0, w_1, \\dots, w_n$ que minimice una función de pérdida $J_w$ que depende de los valores reales ($y_i$) y los estimados ($\\hat{y}_i=w_0 + \\mathbf{w}^T \\cdot \\mathbf{x_i}$) por (\\ref{eq:regresion_lineal}). Una función de pérdida muy utilizada en los modelos de regresión lineal es el error cuadrático medio, cuya expresión es la siguiente: \n",
    "\n",
    "$J_w = \\frac{1}{m}\\sum_{i=1}^m(\\hat{y}_i - y_i)^2$\n",
    "\n",
    "La minimización de la función de pérdida se puede realizar por diferentes métodos cuyo estudio queda fuera del objetivo de esta práctica y para lo que se remite al estudiante a la bibliografía de la asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería sklearn proporciona el módulo linear_model que incluye la clase LinearRegression que como otros estimadores de sklearn, implementa las funciones fit y predict. La función \\texttt{fit} acepta como argumentos un array bidimensional con el valor de las variables independientes  y un array que se corresponde con la variable dependiente. Después de ejecutar la función fit, se habrán calculado los pesos de la ecuación. Indicar que la clase posee el argumento booleano fit_intercept que indica si se normaliza las muestras restando la media. Por defecto, fit_intercept=True que implica centrar las muestras restando la media y por tanto $w_0 \\neq 0$ y se puede acceder por medio del atributo intercept_ de la clase . Si se asigna fit_intercept=False, no se centran las muestras y por tanto el valor de $w_0=0$. Los pesos $w_1, \\dots, w_n$ se almacenan en el atributo coef_ de la clase. La función predict realiza el proceso de predicción de los valores de la variable dependiente a partir de un conjunto de datos de entrada expresados como un array bidimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos a utilizar se corresponde con el tiempo de paso en minutos de corredores por 3 puntos de control y el tiempo final en meta. Los campos están separados por ; y no por ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('tiempos-small.csv', sep=';')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos la información y se observa que no hay valores perdidos y son todos númericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste por regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos en características, *X*, y variable respuesta, *y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos.iloc[:,:-1].values\n",
    "y = datos.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos los coeficientes de la regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio para clase:**\n",
    "\n",
    "Buscar en matplotlib como hacer un diagrama de barras y mostrar los tres coeficientes como un diagrama de barras con las etiquetas del eje x con el nombre del coeficiente.\n",
    "\n",
    "Preguntar que implica el valor de cada coeficiente.\n",
    "\n",
    "Posible solución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(3)\n",
    "plt.bar(x, regr.coef_)\n",
    "plt.xticks(x,['w1', 'w2', 'w3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagramas de dispersión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tipo de diagramas muy útil para representar información puntual son los diagramas de dispersión (scatter). Matplotlib permite hacerlos mediante la función scatter. Se puede cambiar el marcador y el color pero es diferente a como se hace con plot. \n",
    "\n",
    "- El color se cambia mediante el argumento \"c\"\n",
    "- El marcador se cambia mediante el argumento \"marker\"\n",
    "\n",
    "En ambos casos los valores que pueden tomar son iguales a los usados con la función para mostrar curvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.randint(10, size=20)\n",
    "x2 = np.random.randint(10, size=20)\n",
    "print(f'coordenadas x1: {x1}')\n",
    "print(f'coordenadas x2: {x2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x1, x2, c='r', marker='*')\n",
    "plt.xlabel('Coordenada $X_1$')\n",
    "plt.ylabel('Coordenada $X_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio para clase:**\n",
    "\n",
    "Dibujar mediante scatter cada una de las columnas P1 a P3 con la salida para comprobar que P3 tiene una mayor relación lineal con el tiempo en meta tal y como han tenido que detectar al ser w3 el valor mayor.\n",
    "\n",
    "Usar el subplot que se vio en la primera clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.scatter(X[:,0], y)\n",
    "plt.title('P1')\n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(X[:,1], y)\n",
    "plt.title('P2')\n",
    "plt.subplot(2,2,3)\n",
    "plt.scatter(X[:,2], y)\n",
    "plt.title('P3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar a realizar el ajuste con intercept_fit a True y a False y comprobar el resultado de los coeficientes y de intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(fit_intercept=True)\n",
    "regr.fit(X,y)\n",
    "print(f'w0: {regr.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(fit_intercept=False)\n",
    "regr.fit(X,y)\n",
    "print(f'w0: {regr.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación mediante regresión lineal\n",
    "\n",
    "Dividir el conjunto de datos en train y test (p. e. 70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar la bondad del modelo de regresión una medida es el la raiz cuadrada del error cuadrático medio RMSE. \n",
    "\n",
    "Sklearn posee la función root_mean_squared_error.\n",
    "\n",
    "### REVISAR SI LA VERSIÓN DE SKLEARN DEL LABORATORIO INCLUYE LA FUNCIÓN ROOT_MEAN_SQUARED_ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'Error: {error:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio de clase:\n",
    "\n",
    "Obtener la regresión con una única variable de los tres P1, P2 y P3 y calcular el RMSE con cada una de ellas. Comprobar los resultados anteriores de valores de coeficientes y de gráficas de dispersión.\n",
    "\n",
    "IMPORTANTE: Los modelos esperan encontrar como conjunto de entrenamiento un array bidimensional por lo que si solo se usa una sola variable para predecir se debe convertir un vector unidimensional en una matriz con una sola columna. Se puede hacer con vector.reshape(-1,1). Dar ejemplo en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.random(10)\n",
    "print(f'Dimensiones de v {v.shape}')\n",
    "\n",
    "# convertir en una matriz de una columna\n",
    "m = v.reshape(-1,1)\n",
    "print(f'dimensiones de v: {m.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posible solución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range(3):\n",
    "    X_train1 = X_train[:,col].reshape(-1,1)\n",
    "    X_test1 = X_test[:,col].reshape(-1,1)\n",
    "\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X_train1, y_train)\n",
    "    y_pred = regr.predict(X_test1)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    print(f'RMSE variable {col+1}: {rmse:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
